{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "from functools import lru_cache, partial\n",
    "from pprint import pprint\n",
    "\n",
    "import gym_trading_env\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import MultiTrade\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gym_trading_env.downloader import download\n",
    "from gym_trading_env.environments import TradingEnv\n",
    "\n",
    "from gym_trading_env.renderer import Renderer\n",
    "from IPython.display import display\n",
    "from ray import train, tune\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.utils import build_dataset, build_market_image,preprocess_data\n",
    "from utils.forecast_utils import build_model_get_data,get_dataset_columns\n",
    "\n",
    "import ray\n",
    "\n",
    "from transformers import (\n",
    "    EarlyStoppingCallback,\n",
    "    PatchTSTConfig,\n",
    "    PatchTSTForPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COIN_PAIRS=['BTC/USDT','ETH/USDT','SOL/USDT','BNB/USDT','XRP/USDT','ADA/USDT',\n",
    "            'ETH/BTC','SOL/ETH','BNB/ETH','XRP/ETH',\"ADA/ETH\",\n",
    "            'SOL/BTC','SOL/BNB',\n",
    "            'XRP/BTC','XRP/BNB',\n",
    "            'ADA/BTC','ADA/BNB',\n",
    "            ]\n",
    "target_pair='ETHUSDT'\n",
    "time_frame=\"1h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSTConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
    "from tsfm_public.toolkit.time_series_forecasting_pipeline import TimeSeriesForecastingPipeline\n",
    "from tsfm_public.toolkit.util import select_by_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=build_market_image(target_pair='ETH/USDT',time_frame='1h',axis=0)\n",
    "data=data.groupby('symbol').apply(lambda x: x[:pd.Timestamp('2024-01-01')])\n",
    "\n",
    "# # data.to_csv('data/binance-market-1h.csv')\n",
    "\n",
    "# data=data.groupby('symbol').apply(lambda x: x[:pd.Timestamp('2024-01-01')])\n",
    "\n",
    "data=data.reset_index(level=0,drop=True).reset_index()\n",
    "data=data[data['symbol']=='ETHUSDT'].copy()\n",
    "data['symbol'].unique()\n",
    "id_columns=['symbol']\n",
    "output_columns,feature_columns,drop_columns=get_dataset_columns(data,id_columns=['symbol'])\n",
    "len(output_columns)+len(data[id_columns[0]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space={\n",
    "            'context_length': tune.choice([c for c in range(24,64,2)]),\n",
    "            'patch_length': tune.choice([c for c in range(2,8,2)]),\n",
    "            'forecast_horizon': tune.choice([c for c in range(2,12,2)]),\n",
    "            'random_mask_ratio':tune.uniform(1e-6, .50),\n",
    "            'd_model': tune.choice([64,128,256]),\n",
    "            'embed_div':tune.choice([1,2,4,8]),\n",
    "            # 'num_attention_heads': tune.choice([c for c in range(18,36,2)]),\n",
    "            'num_hidden_layers': tune.choice([c for c in range(2,12,2)]),\n",
    "            'ffn_dim': tune.choice([64,128,256]),\n",
    "            'dropout': tune.choice([.1,.2,.3,.4,.5]),\n",
    "            'head_dropout': tune.choice([.1,.2,.3,.4,.5]),\n",
    "            'channel_attention': tune.choice([True,False]),\n",
    "\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_data=build_model_get_data(data=data,\n",
    "# #                                 **params)\n",
    "# model_data['train_dataset'].n_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=48\n",
    "num_workers=8\n",
    "data_id=ray.put(data)\n",
    "\n",
    "def objective(params):\n",
    "    batch_size=64\n",
    "    num_workers=1\n",
    "\n",
    "    params.update( {'scaling': 'std',\n",
    "                    'loss': 'mse',\n",
    "                     'pre_norm': True,\n",
    "                    'norm_type': 'batchnorm',\n",
    "                    'id_columns':['symbol'],\n",
    "                    'timestamp_column': \"date_open\",\n",
    "                    'num_attention_heads': int(params['d_model']/params['embed_div'])\n",
    "                    })\n",
    "\n",
    "    data=ray.get(data_id)\n",
    "    model_data=build_model_get_data(data=data,\n",
    "                                    **params)\n",
    "    \n",
    "    model = model_data['model']\n",
    "    train_dataset = model_data['train_dataset']\n",
    "    valid_dataset = model_data['valid_dataset']\n",
    "    test_dataset = model_data['test_dataset']\n",
    "\n",
    "    # train_dataloader=DataLoader(train_dataset)\n",
    "    # valid_dataloader=DataLoader(valid_dataset)\n",
    "    # test_dataloader=DataLoader(test_dataset)\n",
    "    training_args = TrainingArguments(\n",
    "                                    output_dir=f\"forecaster_pretrain/output/\",\n",
    "                                    overwrite_output_dir=True,\n",
    "                                    # learning_rate=0.001,\n",
    "                                    num_train_epochs=1000,\n",
    "                                    do_eval=True,\n",
    "                                    evaluation_strategy=\"epoch\",\n",
    "\n",
    "                                    per_device_train_batch_size=batch_size,\n",
    "                                    per_device_eval_batch_size=batch_size,\n",
    "\n",
    "                                    dataloader_num_workers=num_workers,\n",
    "                                    \n",
    "                                    save_strategy=\"epoch\",\n",
    "                                    logging_strategy=\"epoch\",\n",
    "                                    save_total_limit=3,\n",
    "                                    \n",
    "                                    logging_dir=f\"forecaster_pretrain/logs/\",  # Make sure to specify a logging directory\n",
    "                                    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "                                    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "                                    greater_is_better=False,  # For loss\n",
    "                                    label_names=[\"future_values\"],\n",
    "                                    disable_tqdm=False\n",
    "                                )\n",
    "\n",
    "    # Create the early stopping callback\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=100,  # Number of epochs with no improvement after which to stop\n",
    "        early_stopping_threshold=0.0001,  # Minimum improvement required to consider as improvement\n",
    "    )\n",
    "\n",
    "    # define trainer\n",
    "\n",
    "    trainer = Trainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=valid_dataset,\n",
    "                    callbacks=[early_stopping_callback],\n",
    "                    # compute_metrics=compute_metrics,\n",
    "                        )\n",
    "    trainer.train()\n",
    "    \n",
    "    result=trainer.state.log_history[-1]\n",
    "    # print(result)\n",
    "    obj=trainer.evaluate(test_dataset)\n",
    "    \n",
    "    obj['_metric']=obj['eval_loss']\n",
    "    obj['score']=obj['eval_loss']\n",
    "    # train.report(obj)\n",
    "    return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={x:y.sample() for x,y in search_space.items()}\n",
    "# print(config)\n",
    "# objective(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_str_creator(trial):\n",
    "    return \"{}_{}_forcaster\".format(trial.trainable_name, trial.trial_id)\n",
    "\n",
    "\n",
    "\n",
    "tune_config=tune.TuneConfig(num_samples=6,mode=\"min\",search_alg='hyperopt',\n",
    "                                trial_name_creator=trial_str_creator,\n",
    "                                \n",
    "                                trial_dirname_creator=trial_str_creator,\n",
    "\n",
    "                            )\n",
    "run_config=train.RunConfig(\n",
    "    storage_path='C:/Users/standard/Git/MultiTrader/forecaster_pretrain/Hyperparam_runs/', \n",
    "    name=\"forecaster_experiments\")\n",
    "resource_group = tune.PlacementGroupFactory([{\"GPU\": 1}])\n",
    "# objective_with_resources = tune.with_resources(objective, resource_group)\n",
    "objective_with_resources = tune.with_resources(objective, {\"cpu\": .5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "else:\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id=ray.put(data)\n",
    "print(data_id)\n",
    "tuner = tune.Tuner(objective_with_resources ,\n",
    "                   tune_config=tune_config,\n",
    "\n",
    "                   run_config=run_config,\n",
    "                    param_space=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mget_best_result(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconfig)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)\n",
    "best_params=results.get_best_result(metric=\"score\", mode=\"min\").config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PatchTSTForPrediction.from_pretrained(\"C:/Users/standard/Git/MultiTrader/stacked_pretrain/output/checkpoint-473186\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_df=test_dataset\n",
    "dir(hf_df)\n",
    "x_test=hf_df[0]['past_values']\n",
    "x_future=hf_df[0]['future_values']\n",
    "\n",
    "x_test=x_test.unsqueeze(0)\n",
    "# x.shape\n",
    "# x_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_preds(axes,size,idx,symbol_idx,model):\n",
    "    x_past=hf_df[idx]['past_values'].unsqueeze(0)\n",
    "    x_future=hf_df[idx]['future_values']\n",
    "\n",
    "    x_pred=model(x_past)['prediction_outputs'].squeeze().cpu().detach().numpy()\n",
    "    x_past=x_past.squeeze().cpu().detach().numpy()\n",
    "    x_future=x_future.cpu().detach().numpy()\n",
    "\n",
    "    x_past=x_past[:,symbol_idx].flatten()\n",
    "    x_future=x_future[:,symbol_idx].flatten()\n",
    "    x_pred=x_pred[:,symbol_idx].flatten()\n",
    "\n",
    "    x_true=np.concatenate([x_past,x_future])\n",
    "    forecast_horizon=len(x_pred)\n",
    "    context_length=len(x_true)\n",
    "\n",
    "    x_plot=np.arange(size)\n",
    "    x_plot=x_plot+idx\n",
    "    pred_plot=x_plot[-forecast_horizon:]\n",
    "    y_true=[]\n",
    "    y_hat=[]\n",
    "    for i in tqdm(range(idx,idx+size)):\n",
    "        y_true.append(x_true[-1])\n",
    "        \n",
    "\n",
    "    axes.scatter(x_plot[-1],x_true[-1], color=\"blue\",label='True')\n",
    "    axes.scatter(pred_plot[-1],x_pred[-1], color=\"red\",label='Pred' ,alpha=0.5)\n",
    "    \n",
    "\n",
    "    plot_id=48\n",
    "    fig, axes = plt.subplots()\n",
    "    for i in tqdm(range(idx,idx+48)):\n",
    "        _plot_preds(axes,idx=i,symbol_idx=2,model=model)\n",
    "        \n",
    "        if i==0:\n",
    "            fig.show()\n",
    "        else:\n",
    "            fig.canvas.draw()\n",
    "        fig.legend()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size=forecast_horizon +context_length\n",
    "plot_size\n",
    "pred_size=x_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_plot=np.arange(plot_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=-1\n",
    "\n",
    "plt.plot(x_plot[:-forecast_horizon],x_test[:,idx])\n",
    "plt.plot(x_plot[-forecast_horizon:],x_pred[:,idx],label='Pred')\n",
    "plt.plot(x_plot[-forecast_horizon:],x_true[:,idx],label='True')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate(x\n",
    "#                  )\n",
    "# model=trainer.model\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=trainer.prediction_step(hf_df[0]).predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(\"Test result:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
