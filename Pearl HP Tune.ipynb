{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_environments\n",
    "from utils import pearl_utils\n",
    "from configs import defaults\n",
    "from utils.reward_functions import log_reward_function,cumulative_reward_function,sharpe_reward_function\n",
    "from utils. utils import make_hidden_dims\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from Pearl.pearl.utils.instantiations.environments.gym_environment import GymEnvironment\n",
    "from Pearl.pearl.utils.functional_utils.train_and_eval.online_learning import \\\n",
    "    online_learning\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 20\n",
      "Seed set to 17\n",
      "Seed set to 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/binanceus-DOGEUSDT-1h.pkl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 11337.14it/s]\n",
      "1it [00:00, 17.78it/s]\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b8396ec7ae40b49716dd0179b7e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f9b552999d4dc8878135aaa585113d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5aa0b7d9ccf43c9ae63833dafb84af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-20 16:00:00 2024-11-19 16:00:00\n"
     ]
    }
   ],
   "source": [
    "reward_functions=[log_reward_function,cumulative_reward_function,sharpe_reward_function]\n",
    "train_env,test_env=make_environments.make_envs(reward_function=log_reward_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOGEUSDT_train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp=train_env.positions\n",
    "train_env.action_space.n\n",
    "train_env.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 64, 64]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hidden_dims(n_layers=3, n_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=pearl_utils.create_ddqn_model(\n",
    "\n",
    "        observation_space_dim=train_env.observation_space.shape[0], \n",
    "        action_space_dim=train_env.action_space.n,\n",
    "        hidden_dims=[64,64, 64], \n",
    "        training_rounds=20,\n",
    "        learning_rate = 0.001,\n",
    "        discount_factor = 0.99,\n",
    "        batch_size = 128,\n",
    "        target_update_freq = 10,\n",
    "        soft_update_tau = 0.75,  # a value of 1 indicates no soft updates\n",
    "        is_conservative = False,\n",
    "        conservative_alpha = False,\n",
    "        replay_buffer_size = 10_000,\n",
    "        lstm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30,), np.int64(2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.observation_space.shape,train_env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=GymEnvironment(train_env)\n",
    "\n",
    "obs,action_space=env.reset()\n",
    "agent.reset(   obs, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done = False\n",
    "# while not done:\n",
    "#     action = agent.act(exploit=False)\n",
    "#     action_result = env.step(action)\n",
    "    \n",
    "#     agent.observe(action_result)\n",
    "#     loss=agent.learn()\n",
    "\n",
    "#     done = action_result.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090364bb825249ca84cf01a26c3d394e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = online_learning(\n",
    "        agent=agent,\n",
    "        env=env,\n",
    "        # number_of_episodes=10,\n",
    "        number_of_steps=168,\n",
    "        print_every_x_episodes=2,   # print returns after every 10 episdoes\n",
    "        print_every_x_steps=1,   # print returns after every 10 episdoes\n",
    "        learn_every_k_steps=20,   # print returns after every 10 episdoes\n",
    "        learn_after_episode=False,\n",
    "        record_period=169,   # instead of updating after every environment interaction, Q networks are updates at the end of each episode\n",
    "        seed=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33//1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def objective_function(trial):\n",
    " \n",
    "    reward_id=trial.suggest_categorical('reward_function', [0,1,2])\n",
    "    algo=trial.suggest_categorical('algorithm', ['dqn','ddqn'])    \n",
    "\n",
    "    # reward_id=0\n",
    "    \n",
    "    reward_func=reward_functions[reward_id]\n",
    "    train_env.reward_func=reward_func\n",
    "    test_env.reward_func=reward_func\n",
    "    \n",
    "    observation_space_dim=train_env.observation_space.shape[0]\n",
    "    action_space_dim=len(train_env.positions)\n",
    "    n_layers=trial.suggest_int('n_layers', 1, 3)\n",
    "    n_units=trial.suggest_categorical('n_units', [64,128,256,512])\n",
    "    \n",
    "    hidden_dims=make_hidden_dims(n_layers= n_layers, n_units=n_units)\n",
    "    \n",
    "    search_space={\n",
    "                'observation_space_dim': observation_space_dim,\n",
    "                'action_space_dim': action_space_dim,\n",
    "                'hidden_dims': hidden_dims,\n",
    "                'training_rounds': trial.suggest_int('training_rounds', 5, 30),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-4),\n",
    "                'discount_factor': trial.suggest_float('discount_factor', 0.8, 0.99), # gamma (greediness)\n",
    "                'batch_size': trial.suggest_categorical('batch_size', [64, 128]),\n",
    "                'target_update_freq': trial.suggest_categorical('target_update_freq', [1, 5, 10, 24]),\n",
    "                'soft_update_tau': trial.suggest_float('soft_update_tau', 0.1, .99), \n",
    "                'is_conservative': trial.suggest_categorical('is_conservative', [True, False]),\n",
    "                'lstm': trial.suggest_categorical('lstm', [True, False]),\n",
    "                'conservative_alpha': trial.suggest_float('conservative_alpha', 0.5, 1.0),\n",
    "                }\n",
    "\n",
    "    learning_space={'learn_after_episode':trial.suggest_categorical('learn_after_episode', [True, False]),\n",
    "                    'learning_steps':trial.suggest_int('learning_steps', 10, 89),\n",
    "                    'n_epochs':trial.suggest_categorical('n_epochs',[100,500]),\n",
    "                    }\n",
    "    #\n",
    "    # print('n_epochs',n_epochs)\n",
    "    if algo=='dqn':\n",
    "        agent=pearl_utils.create_dqn_model(**search_space)\n",
    "    elif algo=='ddqn':\n",
    "        agent=pearl_utils.create_ddqn_model(**search_space)\n",
    "\n",
    "        \n",
    "    agent=pearl_utils.train_pearl_model(agent,train_env,**learning_space)\n",
    "    profit,n_trades=pearl_utils.test_pearl_model(agent,test_env)\n",
    "    objectives={'profit':profit,'n_trades':n_trades}\n",
    "\n",
    "    print('profit',profit,'n_trades',n_trades)\n",
    "\n",
    "    return profit,n_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=defaults.model_name\n",
    "model_name\n",
    "\n",
    "study_name=f\"{defaults.model_name}\"\n",
    "storage_name=\"sqlite:///PearlHPTuning.sqlite3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-19 15:52:15,194] Using an existing study with name 'DOGEUSDTSPOT' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study=create_study(study_name=study_name, \n",
    "             storage=storage_name, \n",
    "             load_if_exists=True,\n",
    "             directions=['maximize','maximize'],\n",
    "             sampler=TPESampler()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710060aecf4a47a48d304f940b69485a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [04:58<?, ?it/s]\n",
      "[I 2024-11-19 15:59:22,367] Trial 0 finished with values: [1423.0532380485854, 0.46] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 256, 'training_rounds': 8, 'learning_rate': 3.757902105533474e-05, 'discount_factor': 0.9259513955826991, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.5443969708496746, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.9096580075756356, 'learn_after_episode': False, 'learning_steps': 74, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1423.0532380485854 n_trades 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6026db05db054df98e03e5cd766efb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [52:03<?, ?it/s]\n",
      "[I 2024-11-19 16:53:47,299] Trial 1 finished with values: [1044.8420718893076, 70.84] and parameters: {'reward_function': 2, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 20, 'learning_rate': 5.351602134066019e-05, 'discount_factor': 0.8254778989193878, 'batch_size': 128, 'target_update_freq': 24, 'soft_update_tau': 0.6142957062398715, 'is_conservative': True, 'lstm': True, 'conservative_alpha': 0.6642486751622055, 'learn_after_episode': False, 'learning_steps': 75, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1044.8420718893076 n_trades 70.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d4d9707353455e98ec64228bdc1d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [06:08<?, ?it/s]\n",
      "[I 2024-11-19 17:02:14,735] Trial 2 finished with values: [1024.4878989919725, 5.57] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 256, 'training_rounds': 26, 'learning_rate': 9.253466472219328e-05, 'discount_factor': 0.8462934098248838, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.6713495949030748, 'is_conservative': True, 'lstm': True, 'conservative_alpha': 0.6952673480450033, 'learn_after_episode': True, 'learning_steps': 65, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1024.4878989919725 n_trades 5.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5d50f032dc42969eecbe35ede3754c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:35<?, ?it/s]\n",
      "[I 2024-11-19 17:02:52,871] Trial 3 finished with values: [1093.871802437584, 40.24] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 256, 'training_rounds': 21, 'learning_rate': 3.2507681034328363e-05, 'discount_factor': 0.9255955810614617, 'batch_size': 128, 'target_update_freq': 24, 'soft_update_tau': 0.6723693771058151, 'is_conservative': False, 'lstm': False, 'conservative_alpha': 0.7479824879039227, 'learn_after_episode': False, 'learning_steps': 29, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1093.871802437584 n_trades 40.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5995e6b079049aab7f18273911f5afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:38<?, ?it/s]\n",
      "[I 2024-11-19 17:03:33,384] Trial 4 finished with values: [1165.4043903121283, 27.56] and parameters: {'reward_function': 1, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 64, 'training_rounds': 29, 'learning_rate': 5.722490854629807e-05, 'discount_factor': 0.9818046811053813, 'batch_size': 128, 'target_update_freq': 5, 'soft_update_tau': 0.21833797964764654, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6992223728177329, 'learn_after_episode': True, 'learning_steps': 10, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1165.4043903121283 n_trades 27.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c2468dc99e4fae87fa4fb8e3de2231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:30<?, ?it/s]\n",
      "[I 2024-11-19 17:04:06,578] Trial 5 finished with values: [1082.2632626335967, 59.14] and parameters: {'reward_function': 2, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 256, 'training_rounds': 21, 'learning_rate': 7.783108001276111e-05, 'discount_factor': 0.8812978598926988, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.30570536884395816, 'is_conservative': False, 'lstm': False, 'conservative_alpha': 0.7481089744378919, 'learn_after_episode': False, 'learning_steps': 23, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1082.2632626335967 n_trades 59.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04ec4549e36444ca5f16ac130083891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [09:32<?, ?it/s]\n",
      "[I 2024-11-19 17:13:43,343] Trial 6 finished with values: [1183.9876748505383, 61.05] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 512, 'training_rounds': 29, 'learning_rate': 4.9043254065469676e-05, 'discount_factor': 0.8448209410243246, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.6880326022560119, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.52273543943938, 'learn_after_episode': False, 'learning_steps': 24, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1183.9876748505383 n_trades 61.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ca8391594d4b369d65bdd66426c34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [01:33<?, ?it/s]\n",
      "[I 2024-11-19 17:15:20,101] Trial 7 finished with values: [1166.0221371255036, 45.1] and parameters: {'reward_function': 2, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 15, 'learning_rate': 7.622343360638977e-05, 'discount_factor': 0.875473211887314, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.39089679827155976, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.7521636961518408, 'learn_after_episode': False, 'learning_steps': 80, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1166.0221371255036 n_trades 45.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c506e4c5eea94f8faa3518437b86d67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:04<?, ?it/s]\n",
      "[I 2024-11-19 17:15:27,686] Trial 8 finished with values: [1042.3869070368567, 66.95] and parameters: {'reward_function': 1, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 128, 'training_rounds': 11, 'learning_rate': 2.394721427170762e-05, 'discount_factor': 0.9528450420131132, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.36652749574330545, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.9299078413804187, 'learn_after_episode': True, 'learning_steps': 40, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1042.3869070368567 n_trades 66.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3312ad5db54cd9899e4ddb633d468f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:05<?, ?it/s]\n",
      "[I 2024-11-19 17:15:35,026] Trial 9 finished with values: [1080.1497512621145, 88.97] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 64, 'training_rounds': 11, 'learning_rate': 9.537722608965365e-05, 'discount_factor': 0.9458174345070368, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.9870547152023663, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8693676725350628, 'learn_after_episode': False, 'learning_steps': 82, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1080.1497512621145 n_trades 88.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425019d4fbf645799ab8b671513d0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [30:49<?, ?it/s]\n",
      "[I 2024-11-19 17:48:58,398] Trial 10 finished with values: [1065.0813876069421, 4.46] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 512, 'training_rounds': 26, 'learning_rate': 2.9731165265082507e-06, 'discount_factor': 0.8071178099647397, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.9117615015257374, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.5066230461006795, 'learn_after_episode': True, 'learning_steps': 56, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1065.0813876069421 n_trades 4.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0cb4c5bee74756b8cb26f63c180134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:03<?, ?it/s]\n",
      "[I 2024-11-19 17:49:03,895] Trial 11 finished with values: [1199.141291531122, 16.3] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 1, 'n_units': 64, 'training_rounds': 5, 'learning_rate': 9.864504483163224e-05, 'discount_factor': 0.9891893876758102, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.9691028953452985, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8487880382937174, 'learn_after_episode': False, 'learning_steps': 85, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1199.141291531122 n_trades 16.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19728f5ccfe94dcfabecbe67374906f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:07<?, ?it/s]\n",
      "[I 2024-11-19 17:49:13,508] Trial 12 finished with values: [1185.9230533919385, 37.08] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 64, 'training_rounds': 14, 'learning_rate': 7.186735171315688e-05, 'discount_factor': 0.9208608914497881, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.8421308278542015, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.9801401499189992, 'learn_after_episode': False, 'learning_steps': 48, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1185.9230533919385 n_trades 37.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bd20dbffe945448b70580938212df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:06<?, ?it/s]\n",
      "[I 2024-11-19 17:49:22,346] Trial 13 finished with values: [1002.653571003455, 62.07] and parameters: {'reward_function': 1, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 64, 'training_rounds': 12, 'learning_rate': 6.413776758799948e-05, 'discount_factor': 0.9555366409178272, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.8172748043342444, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8408321820104281, 'learn_after_episode': False, 'learning_steps': 65, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1002.653571003455 n_trades 62.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4184ce2531434308b9abb62b94e78c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:30<?, ?it/s]\n",
      "[I 2024-11-19 17:49:54,977] Trial 14 finished with values: [1023.5906522572063, 27.27] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 128, 'training_rounds': 8, 'learning_rate': 8.652403474824905e-05, 'discount_factor': 0.8995347922292788, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.7779104200455872, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5839633723681885, 'learn_after_episode': False, 'learning_steps': 88, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1023.5906522572063 n_trades 27.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc59f24e7d2441338afd25c86b6b4e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:10<?, ?it/s]\n",
      "[I 2024-11-19 17:50:07,223] Trial 15 finished with values: [1346.793678570731, 1.27] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 64, 'training_rounds': 17, 'learning_rate': 7.063019511583738e-06, 'discount_factor': 0.9515703787427277, 'batch_size': 64, 'target_update_freq': 10, 'soft_update_tau': 0.49589638340411674, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8473691946647696, 'learn_after_episode': False, 'learning_steps': 37, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1346.793678570731 n_trades 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988d2dc0019a450e9450d0d3061d119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [41:55<?, ?it/s]\n",
      "[I 2024-11-19 18:43:14,944] Trial 16 finished with values: [993.4068317418579, 9.4] and parameters: {'reward_function': 1, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 64, 'training_rounds': 9, 'learning_rate': 4.283202053181672e-05, 'discount_factor': 0.8548069105534023, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.9799243672226613, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.9851693464643849, 'learn_after_episode': True, 'learning_steps': 61, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 993.4068317418579 n_trades 9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463d9ac743e2422a84b49f4baf0fd566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:27<?, ?it/s]\n",
      "[I 2024-11-19 18:43:44,728] Trial 17 finished with values: [1084.1208438465244, 62.79] and parameters: {'reward_function': 2, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 128, 'training_rounds': 16, 'learning_rate': 8.608404109402027e-05, 'discount_factor': 0.905484414818783, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.10811990246677433, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.7962721485322966, 'learn_after_episode': False, 'learning_steps': 15, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1084.1208438465244 n_trades 62.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e4e6f9e4724d3884a86bca2bab8772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:10<?, ?it/s]\n",
      "[I 2024-11-19 18:43:58,586] Trial 18 finished with values: [1047.0246470901593, 58.27] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 5, 'learning_rate': 1.5735626769690555e-05, 'discount_factor': 0.9635275141207652, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.7473368620916079, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.9079975010218981, 'learn_after_episode': False, 'learning_steps': 46, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1047.0246470901593 n_trades 58.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc98819884df409496faf02d94313a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [1:08:08<?, ?it/s]\n",
      "[I 2024-11-19 19:54:04,505] Trial 19 finished with values: [1066.381803381373, 0.69] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 64, 'training_rounds': 12, 'learning_rate': 6.432829813945095e-05, 'discount_factor': 0.937254959805319, 'batch_size': 128, 'target_update_freq': 24, 'soft_update_tau': 0.8957363830381931, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.6281314664045141, 'learn_after_episode': True, 'learning_steps': 72, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1066.381803381373 n_trades 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3033d0b46a444487bbd395913091d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:09<?, ?it/s]\n",
      "[I 2024-11-19 19:54:16,821] Trial 20 finished with values: [1196.3365560571085, 44.86] and parameters: {'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 64, 'training_rounds': 19, 'learning_rate': 4.671577796086594e-05, 'discount_factor': 0.8689602407740552, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.46471978696204874, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5718231368869076, 'learn_after_episode': False, 'learning_steps': 57, 'n_epochs': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1196.3365560571085 n_trades 44.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce44252331be48afbaa0d671abcecd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [04:07<?, ?it/s]\n",
      "[I 2024-11-19 19:58:28,375] Trial 21 finished with values: [1052.31127842453, 66.97] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 512, 'training_rounds': 30, 'learning_rate': 4.966286095852234e-05, 'discount_factor': 0.8677280365985045, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.7042853356512264, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5228885209594548, 'learn_after_episode': False, 'learning_steps': 56, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1052.31127842453 n_trades 66.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76d231ff8964772a62f5e3b0b69f3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [03:57<?, ?it/s]\n",
      "[I 2024-11-19 20:02:29,627] Trial 22 finished with values: [1180.8020672187827, 81.11] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 24, 'learning_rate': 4.403085106429863e-05, 'discount_factor': 0.8348577340944441, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.507281071521004, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5685225047523212, 'learn_after_episode': False, 'learning_steps': 32, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1180.8020672187827 n_trades 81.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb7a3d6f90448fb8aed18b9d73537c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [03:58<?, ?it/s]\n",
      "[I 2024-11-19 20:06:32,651] Trial 23 finished with values: [1065.1831652154779, 66.57] and parameters: {'reward_function': 2, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 24, 'learning_rate': 2.9896398653929366e-05, 'discount_factor': 0.8027791445182954, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.43352138948368835, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5692993155464433, 'learn_after_episode': False, 'learning_steps': 33, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1065.1831652154779 n_trades 66.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff55206a7ffa478eb5dc9e0622a265ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [38:45<?, ?it/s]\n",
      "[I 2024-11-19 20:47:23,404] Trial 24 finished with values: [1089.6385707965628, 1.27] and parameters: {'reward_function': 1, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 24, 'learning_rate': 2.3320327577625975e-05, 'discount_factor': 0.8275103606272973, 'batch_size': 128, 'target_update_freq': 1, 'soft_update_tau': 0.5539504725706653, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.5901692244540463, 'learn_after_episode': True, 'learning_steps': 20, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1089.6385707965628 n_trades 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aac0d66417c493e9407ba1e91785cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [02:32<?, ?it/s]\n",
      "[I 2024-11-19 20:49:59,671] Trial 25 finished with values: [1183.8729654735441, 106.54] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 19, 'learning_rate': 4.242483171059622e-05, 'discount_factor': 0.8318353760943185, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.49169390605199403, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6258847103375103, 'learn_after_episode': False, 'learning_steps': 41, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1183.8729654735441 n_trades 106.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63eb5a819a447c48515766ece2cdecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [26:08<?, ?it/s]\n",
      "[I 2024-11-19 21:18:07,596] Trial 26 finished with values: [1011.6010159956437, 100.4] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 128, 'training_rounds': 18, 'learning_rate': 8.16475393118449e-06, 'discount_factor': 0.8172805307946088, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.49203632385812635, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.6421570584037625, 'learn_after_episode': True, 'learning_steps': 38, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1011.6010159956437 n_trades 100.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdf19ab52744d42b7cd9d31755e4caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [02:10<?, ?it/s]\n",
      "[I 2024-11-19 21:20:22,222] Trial 27 finished with values: [974.927443120815, 84.96] and parameters: {'reward_function': 1, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 18, 'learning_rate': 1.669515422838089e-05, 'discount_factor': 0.8619084584280354, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.28465611983492817, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6167848019804593, 'learn_after_episode': False, 'learning_steps': 42, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 974.927443120815 n_trades 84.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973ca1d0e0fe48b0beeff256c7e4583c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [01:57<?, ?it/s]\n",
      "[I 2024-11-19 21:22:23,040] Trial 28 finished with values: [1108.355859301906, 51.76] and parameters: {'reward_function': 2, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 19, 'learning_rate': 6.225399058859204e-05, 'discount_factor': 0.8822318739602012, 'batch_size': 64, 'target_update_freq': 10, 'soft_update_tau': 0.46161826363872105, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6887439020791601, 'learn_after_episode': False, 'learning_steps': 55, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1108.355859301906 n_trades 51.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ca04da58af4813806c1dc731d61b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [1:05:02<?, ?it/s]\n",
      "[I 2024-11-19 22:29:59,747] Trial 29 finished with values: [1103.6676968356815, 44.92] and parameters: {'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 1, 'n_units': 256, 'training_rounds': 16, 'learning_rate': 3.681561941184994e-05, 'discount_factor': 0.8167826783794293, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.5780146554966249, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.7906856638651517, 'learn_after_episode': False, 'learning_steps': 51, 'n_epochs': 500}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profit 1103.6676968356815 n_trades 44.92\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective_function, n_trials=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, state=TrialState.COMPLETE, values=[1423.0532380485854, 0.46], datetime_start=datetime.datetime(2024, 11, 19, 15, 52, 15, 747219), datetime_complete=datetime.datetime(2024, 11, 19, 15, 59, 22, 364972), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 256, 'training_rounds': 8, 'learning_rate': 3.757902105533474e-05, 'discount_factor': 0.9259513955826991, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.5443969708496746, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.9096580075756356, 'learn_after_episode': False, 'learning_steps': 74, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=1, value=None),\n",
       " FrozenTrial(number=6, state=TrialState.COMPLETE, values=[1183.9876748505383, 61.05], datetime_start=datetime.datetime(2024, 11, 19, 17, 4, 6, 582093), datetime_complete=datetime.datetime(2024, 11, 19, 17, 13, 43, 339912), params={'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 512, 'training_rounds': 29, 'learning_rate': 4.9043254065469676e-05, 'discount_factor': 0.8448209410243246, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.6880326022560119, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.52273543943938, 'learn_after_episode': False, 'learning_steps': 24, 'n_epochs': 500}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=7, value=None),\n",
       " FrozenTrial(number=11, state=TrialState.COMPLETE, values=[1199.141291531122, 16.3], datetime_start=datetime.datetime(2024, 11, 19, 17, 48, 58, 402172), datetime_complete=datetime.datetime(2024, 11, 19, 17, 49, 3, 892294), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 1, 'n_units': 64, 'training_rounds': 5, 'learning_rate': 9.864504483163224e-05, 'discount_factor': 0.9891893876758102, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.9691028953452985, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8487880382937174, 'learn_after_episode': False, 'learning_steps': 85, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=12, value=None),\n",
       " FrozenTrial(number=15, state=TrialState.COMPLETE, values=[1346.793678570731, 1.27], datetime_start=datetime.datetime(2024, 11, 19, 17, 49, 54, 980687), datetime_complete=datetime.datetime(2024, 11, 19, 17, 50, 7, 220355), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 64, 'training_rounds': 17, 'learning_rate': 7.063019511583738e-06, 'discount_factor': 0.9515703787427277, 'batch_size': 64, 'target_update_freq': 10, 'soft_update_tau': 0.49589638340411674, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8473691946647696, 'learn_after_episode': False, 'learning_steps': 37, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=16, value=None),\n",
       " FrozenTrial(number=20, state=TrialState.COMPLETE, values=[1196.3365560571085, 44.86], datetime_start=datetime.datetime(2024, 11, 19, 19, 54, 4, 508604), datetime_complete=datetime.datetime(2024, 11, 19, 19, 54, 16, 818709), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 64, 'training_rounds': 19, 'learning_rate': 4.671577796086594e-05, 'discount_factor': 0.8689602407740552, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.46471978696204874, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5718231368869076, 'learn_after_episode': False, 'learning_steps': 57, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=21, value=None),\n",
       " FrozenTrial(number=25, state=TrialState.COMPLETE, values=[1183.8729654735441, 106.54], datetime_start=datetime.datetime(2024, 11, 19, 20, 47, 23, 407944), datetime_complete=datetime.datetime(2024, 11, 19, 20, 49, 59, 667645), params={'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 19, 'learning_rate': 4.242483171059622e-05, 'discount_factor': 0.8318353760943185, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.49169390605199403, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6258847103375103, 'learn_after_episode': False, 'learning_steps': 41, 'n_epochs': 500}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=26, value=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"Best value: {study.best_value} (params: {study.best_params})\")\n",
    "best_trials=study.best_trials\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials=study.best_trials\n",
    "best_trail=best_trials[3]\n",
    "best_params=best_trail.params\n",
    "reward_func=reward_functions[best_params.pop('reward_function')]\n",
    "train_env.reward_func=reward_func\n",
    "test_env.reward_func=reward_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'training_rounds': 17,\n",
       "  'learning_rate': 7.063019511583738e-06,\n",
       "  'discount_factor': 0.9515703787427277,\n",
       "  'batch_size': 64,\n",
       "  'target_update_freq': 10,\n",
       "  'soft_update_tau': 0.49589638340411674,\n",
       "  'is_conservative': True,\n",
       "  'conservative_alpha': 0.8473691946647696,\n",
       "  'hidden_dims': [64, 64],\n",
       "  'lstm': False},\n",
       " {'learn_after_episode': False, 'learning_steps': 37, 'n_epochs': 100})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo=best_params.pop('algorithm')\n",
    "\n",
    "learning_params={'learn_after_episode':best_params.pop('learn_after_episode'),\n",
    "                    'learning_steps':best_params.pop('learning_steps'),\n",
    "                    'n_epochs':best_params.pop('n_epochs'),\n",
    "                    }\n",
    "best_params['hidden_dims']=make_hidden_dims(n_layers=best_params.pop('n_layers'),n_units=best_params.pop('n_units'))\n",
    "best_params['lstm']=best_params.pop('lstm')\n",
    "if algo=='dqn':\n",
    "    agent=pearl_utils.create_dqn_model(**best_params)\n",
    "elif algo=='ddqn':\n",
    "    agent=pearl_utils.create_ddqn_model(**best_params)\n",
    "\n",
    "best_params,learning_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7bb504c4774e20bab81ed512e4d149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x32 and 27x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sebastiancoombs/Documents/Git/MultiTrader/Pearl HP Tune.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sebastiancoombs/Documents/Git/MultiTrader/Pearl%20HP%20Tune.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m=\u001b[39mpearl_utils\u001b[39m.\u001b[39;49mtrain_pearl_model(agent,train_env,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mlearning_params)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancoombs/Documents/Git/MultiTrader/Pearl%20HP%20Tune.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m profit,n_trades\u001b[39m=\u001b[39mpearl_utils\u001b[39m.\u001b[39mtest_pearl_model(agent,test_env)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancoombs/Documents/Git/MultiTrader/Pearl%20HP%20Tune.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m agent\u001b[39m=\u001b[39mpearl_utils\u001b[39m.\u001b[39mtrain_pearl_model(agent,test_env,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlearning_params)\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/utils/pearl_utils.py:134\u001b[0m, in \u001b[0;36mtrain_pearl_model\u001b[0;34m(agent, env, n_epochs, learn_after_episode, learning_steps)\u001b[0m\n\u001b[1;32m    132\u001b[0m env\u001b[39m=\u001b[39mGymEnvironment(env)\n\u001b[1;32m    133\u001b[0m bar\u001b[39m=\u001b[39mtqdm(\u001b[39mrange\u001b[39m(n_epochs))\n\u001b[0;32m--> 134\u001b[0m info \u001b[39m=\u001b[39m online_learning(\n\u001b[1;32m    135\u001b[0m     agent\u001b[39m=\u001b[39;49magent,\n\u001b[1;32m    136\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m    137\u001b[0m     number_of_episodes\u001b[39m=\u001b[39;49mn_epochs \u001b[39mif\u001b[39;49;00m learn_after_episode\u001b[39m==\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    138\u001b[0m     number_of_steps\u001b[39m=\u001b[39;49m\u001b[39m168\u001b[39;49m\u001b[39m*\u001b[39;49mn_epochs \u001b[39mif\u001b[39;49;00m learn_after_episode\u001b[39m==\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    139\u001b[0m     learn_after_episode\u001b[39m=\u001b[39;49mlearn_after_episode,  \n\u001b[1;32m    140\u001b[0m     print_every_x_steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    141\u001b[0m     print_every_x_episodes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,   \u001b[39m# print returns after every 10 episdoes\u001b[39;49;00m\n\u001b[1;32m    142\u001b[0m \n\u001b[1;32m    143\u001b[0m     learn_every_k_steps\u001b[39m=\u001b[39;49m learning_steps \u001b[39mif\u001b[39;49;00m learn_after_episode\u001b[39m==\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, \u001b[39m# print returns after every 10 steps\u001b[39;49;00m\n\u001b[1;32m    144\u001b[0m     record_period\u001b[39m=\u001b[39;49m\u001b[39m169\u001b[39;49m,\n\u001b[1;32m    145\u001b[0m         \u001b[39m# instead of updating after every environment interaction, Q networks are updates at the end of each episode\u001b[39;49;00m\n\u001b[1;32m    146\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m agent\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/utils/functional_utils/train_and_eval/online_learning.py:121\u001b[0m, in \u001b[0;36monline_learning\u001b[0;34m(agent, env, number_of_episodes, number_of_steps, learn_after_episode, learn_every_k_steps, print_every_x_episodes, print_every_x_steps, seed, record_period)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m number_of_episodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m total_episodes \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m number_of_episodes:\n\u001b[1;32m    120\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[39mif\u001b[39;00m number_of_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m total_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m number_of_steps:\n\u001b[1;32m    122\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    123\u001b[0m old_total_steps \u001b[39m=\u001b[39m total_steps\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/utils/functional_utils/train_and_eval/online_learning.py:292\u001b[0m, in \u001b[0;36mrun_episode\u001b[0;34m(agent, env, learn, exploit, learn_after_episode, learn_every_k_steps, total_steps, seed)\u001b[0m\n\u001b[1;32m    290\u001b[0m agent\u001b[39m.\u001b[39mreset(observation, action_space)\n\u001b[1;32m    291\u001b[0m cum_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 292\u001b[0m cum_cost \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    293\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    294\u001b[0m episode_steps \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/pearl_agent.py:157\u001b[0m, in \u001b[0;36mPearlAgent.act\u001b[0;34m(self, exploit)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(safe_action_space, DiscreteActionSpace)\n\u001b[1;32m    155\u001b[0m     safe_action_space\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 157\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_learner\u001b[39m.\u001b[39;49mact(\n\u001b[1;32m    158\u001b[0m     subjective_state_to_be_used, safe_action_space, exploit\u001b[39m=\u001b[39;49mexploit  \u001b[39m# pyre-fixme[6]\u001b[39;49;00m\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_latest_action \u001b[39m=\u001b[39m action\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/policy_learners/sequential_decision_making/deep_td_learning.py:219\u001b[0m, in \u001b[0;36mDeepTDLearning.act\u001b[0;34m(self, subjective_state, available_action_space, exploit)\u001b[0m\n\u001b[1;32m    214\u001b[0m actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_representation_module(\n\u001b[1;32m    215\u001b[0m     available_action_space\u001b[39m.\u001b[39mactions_batch\u001b[39m.\u001b[39mto(states_repeated)\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m \u001b[39m# (action_space_size, action_dim)\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Q\u001b[39m.\u001b[39;49mget_q_values(states_repeated, actions)\n\u001b[1;32m    220\u001b[0m \u001b[39m# this does a forward pass since all avaialble\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m# actions are already stacked together\u001b[39;00m\n\u001b[1;32m    223\u001b[0m exploit_action_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(q_values)\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/neural_networks/sequential_decision_making/q_value_networks.py:155\u001b[0m, in \u001b[0;36mVanillaQValueNetwork.get_q_values\u001b[0;34m(self, state_batch, action_batch, curr_available_actions_batch)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_q_values\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     state_batch: Tensor,\n\u001b[1;32m    151\u001b[0m     action_batch: Tensor,\n\u001b[1;32m    152\u001b[0m     curr_available_actions_batch: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    154\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([state_batch, action_batch], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Git/MultiTrader/Pearl/pearl/neural_networks/sequential_decision_making/q_value_networks.py:146\u001b[0m, in \u001b[0;36mVanillaQValueNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pearlenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x32 and 27x64)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "agent=pearl_utils.train_pearl_model(agent,train_env,**learning_params)\n",
    "\n",
    "profit,n_trades=pearl_utils.test_pearl_model(agent,test_env)\n",
    "\n",
    "agent=pearl_utils.train_pearl_model(agent,test_env,**learning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run ./Pearl train_agent.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
