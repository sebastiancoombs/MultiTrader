{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_environments\n",
    "from utils import pearl_utils\n",
    "from configs  import defaults\n",
    "\n",
    "from utils.reward_functions import log_reward_function,cumulative_reward_function,sharpe_reward_function\n",
    "from utils. utils import make_hidden_dims\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from Pearl.pearl.utils.instantiations.environments.gym_environment import GymEnvironment\n",
    "from Pearl.pearl.utils.functional_utils.train_and_eval.online_learning import online_learning\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=NeuralForecast.load('MultiHeadForecastingModel/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 20\n",
      "Seed set to 17\n",
      "Seed set to 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/binanceus-DOGEUSDT-1h.pkl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 11985.48it/s]\n",
      "1it [00:00, 19.61it/s]\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04c110ce7514970bfa617267ec6b734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3950d8b44f48579f5de500c4ff84fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2fed8d88444ca5aebe3750d1cec9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-21 08:00:00 2024-11-20 08:00:00\n"
     ]
    }
   ],
   "source": [
    "reward_functions=[log_reward_function,cumulative_reward_function,sharpe_reward_function]\n",
    "train_env,test_env=make_environments.make_envs(reward_function=log_reward_function)\n",
    "study_name=f\"{defaults.model_name}\"\n",
    "storage_name=\"sqlite:///PearlHPTuning.sqlite3\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "today=datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "study = optuna.load_study(study_name=study_name,\n",
    "                            storage=storage_name,\n",
    "\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, state=TrialState.COMPLETE, values=[1423.0532380485854, 0.46], datetime_start=datetime.datetime(2024, 11, 19, 15, 52, 15, 747219), datetime_complete=datetime.datetime(2024, 11, 19, 15, 59, 22, 364972), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 256, 'training_rounds': 8, 'learning_rate': 3.757902105533474e-05, 'discount_factor': 0.9259513955826991, 'batch_size': 128, 'target_update_freq': 10, 'soft_update_tau': 0.5443969708496746, 'is_conservative': False, 'lstm': True, 'conservative_alpha': 0.9096580075756356, 'learn_after_episode': False, 'learning_steps': 74, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=1, value=None),\n",
       " FrozenTrial(number=6, state=TrialState.COMPLETE, values=[1183.9876748505383, 61.05], datetime_start=datetime.datetime(2024, 11, 19, 17, 4, 6, 582093), datetime_complete=datetime.datetime(2024, 11, 19, 17, 13, 43, 339912), params={'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 3, 'n_units': 512, 'training_rounds': 29, 'learning_rate': 4.9043254065469676e-05, 'discount_factor': 0.8448209410243246, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.6880326022560119, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.52273543943938, 'learn_after_episode': False, 'learning_steps': 24, 'n_epochs': 500}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=7, value=None),\n",
       " FrozenTrial(number=11, state=TrialState.COMPLETE, values=[1199.141291531122, 16.3], datetime_start=datetime.datetime(2024, 11, 19, 17, 48, 58, 402172), datetime_complete=datetime.datetime(2024, 11, 19, 17, 49, 3, 892294), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 1, 'n_units': 64, 'training_rounds': 5, 'learning_rate': 9.864504483163224e-05, 'discount_factor': 0.9891893876758102, 'batch_size': 64, 'target_update_freq': 24, 'soft_update_tau': 0.9691028953452985, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8487880382937174, 'learn_after_episode': False, 'learning_steps': 85, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=12, value=None),\n",
       " FrozenTrial(number=15, state=TrialState.COMPLETE, values=[1346.793678570731, 1.27], datetime_start=datetime.datetime(2024, 11, 19, 17, 49, 54, 980687), datetime_complete=datetime.datetime(2024, 11, 19, 17, 50, 7, 220355), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 2, 'n_units': 64, 'training_rounds': 17, 'learning_rate': 7.063019511583738e-06, 'discount_factor': 0.9515703787427277, 'batch_size': 64, 'target_update_freq': 10, 'soft_update_tau': 0.49589638340411674, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.8473691946647696, 'learn_after_episode': False, 'learning_steps': 37, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=16, value=None),\n",
       " FrozenTrial(number=20, state=TrialState.COMPLETE, values=[1196.3365560571085, 44.86], datetime_start=datetime.datetime(2024, 11, 19, 19, 54, 4, 508604), datetime_complete=datetime.datetime(2024, 11, 19, 19, 54, 16, 818709), params={'reward_function': 0, 'algorithm': 'ddqn', 'n_layers': 3, 'n_units': 64, 'training_rounds': 19, 'learning_rate': 4.671577796086594e-05, 'discount_factor': 0.8689602407740552, 'batch_size': 64, 'target_update_freq': 5, 'soft_update_tau': 0.46471978696204874, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.5718231368869076, 'learn_after_episode': False, 'learning_steps': 57, 'n_epochs': 100}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=21, value=None),\n",
       " FrozenTrial(number=25, state=TrialState.COMPLETE, values=[1183.8729654735441, 106.54], datetime_start=datetime.datetime(2024, 11, 19, 20, 47, 23, 407944), datetime_complete=datetime.datetime(2024, 11, 19, 20, 49, 59, 667645), params={'reward_function': 0, 'algorithm': 'dqn', 'n_layers': 2, 'n_units': 512, 'training_rounds': 19, 'learning_rate': 4.242483171059622e-05, 'discount_factor': 0.8318353760943185, 'batch_size': 64, 'target_update_freq': 1, 'soft_update_tau': 0.49169390605199403, 'is_conservative': True, 'lstm': False, 'conservative_alpha': 0.6258847103375103, 'learn_after_episode': False, 'learning_steps': 41, 'n_epochs': 500}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'reward_function': CategoricalDistribution(choices=(0, 1, 2)), 'algorithm': CategoricalDistribution(choices=('dqn', 'ddqn')), 'n_layers': IntDistribution(high=3, log=False, low=1, step=1), 'n_units': CategoricalDistribution(choices=(64, 128, 256, 512)), 'training_rounds': IntDistribution(high=30, log=False, low=5, step=1), 'learning_rate': FloatDistribution(high=0.0001, log=False, low=1e-06, step=None), 'discount_factor': FloatDistribution(high=0.99, log=False, low=0.8, step=None), 'batch_size': CategoricalDistribution(choices=(64, 128)), 'target_update_freq': CategoricalDistribution(choices=(1, 5, 10, 24)), 'soft_update_tau': FloatDistribution(high=0.99, log=False, low=0.1, step=None), 'is_conservative': CategoricalDistribution(choices=(True, False)), 'lstm': CategoricalDistribution(choices=(True, False)), 'conservative_alpha': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'learn_after_episode': CategoricalDistribution(choices=(True, False)), 'learning_steps': IntDistribution(high=89, log=False, low=10, step=1), 'n_epochs': CategoricalDistribution(choices=(100, 500))}, trial_id=26, value=None)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"Best value: {study.best_value} (params: {study.best_params})\")\n",
    "best_trials=study.best_trials\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent/pearl_DOGEUSDTSPOT_model.pkl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if -1 in [np.sign(p) for p in test_env.positions]:\n",
    "    market_type='Futures'\n",
    "else:\n",
    "    market_type='Spot'\n",
    "symb=defaults.target_pair.replace('/','')\n",
    "\n",
    "agent_path=f'Agent/pearl_{defaults.model_name}_model.pkl'\n",
    "\n",
    "agent_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-20 08:28:50,709] Using an existing study with name 'DOGEUSDTSPOT' instead of creating a new one.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914cacc6242b4f99a9cf93b308933f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [05:18<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Return AVG Profit: 1049.5455625048523, AVG Number of Trades: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740c785afec04ff28741fdce3890f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_agents={}\n",
    "for i in range(4):\n",
    "    agent,learning_params=pearl_utils.load_agent_from_study(study_path=storage_name,\n",
    "                                            study_name=study_name,\n",
    "                                            action_space_dim=2,\n",
    "                                            observation_space_dim=30,\n",
    "                                            version=i)\n",
    "    \n",
    "    agent,profit,n_trades=pearl_utils.train_production_agent(agent,\n",
    "                                learning_params,\n",
    "                                train_env=train_env,\n",
    "                                test_env=train_env,\n",
    "                                save_path=agent_path)\n",
    "    best_agents[profit]=agent\n",
    "agent=best_agents[max(best_agents)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent,learning_params=pearl_utils.load_agent_from_study(study_path=\"sqlite:///pearl_hyper_parameters.sqlite3\",\n",
    "#                                             study_name='pearl-2024-11-12-hp-search',\n",
    "#                                             action_space_dim=2,\n",
    "#                                             observation_space_dim=30,\n",
    "#                                             version=1)\n",
    "\n",
    "# agent=pearl_utils.train_production_agent(agent,\n",
    "#                              learning_params,\n",
    "#                              train_env=train_env,\n",
    "#                              test_env=train_env,\n",
    "#                              save_path=agent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Return AVG Profit: 1284.8120247137942, AVG Number of Trades: 34.08\n"
     ]
    }
   ],
   "source": [
    "profit,n_trades=pearl_utils.test_pearl_model(agent,test_env)\n",
    "print(f\"Testing Return AVG Profit: {profit}, AVG Number of Trades: {n_trades}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(agent,open(agent_path,'wb'))\n",
    "\n",
    "import Keys\n",
    "\n",
    "s3=boto3.client('s3', aws_access_key_id=Keys.AWS_ACCESS_KEY, aws_secret_access_key=Keys.AWS_SECRET_KEY)\n",
    "s3.upload_file(agent_path,'coinbasetradehistory',agent_path.split('/')[-1],)\n",
    "\n",
    "agent=pickle.load(open(agent_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(agent.policy_learner.state_dict(),open(agent_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=pickle.load(open(agent_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.policy_learner.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agent,learning_params=pearl_utils.load_agent_from_study(study_path=\"sqlite:///pearl_hyper_parameters.sqlite3\",\n",
    "#                                         study_name='pearl-2024-11-12-hp-search',\n",
    "#                                         action_space_dim=2,\n",
    "#                                         observation_space_dim=30)\n",
    "# agent=load_agent_weights(agent,weight_path=agent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Return AVG Profit: 1296.970877901161, AVG Number of Trades: 37.15\n"
     ]
    }
   ],
   "source": [
    "profit,n_trades=pearl_utils.test_pearl_model(agent,test_env)\n",
    "print(f\"Testing Return AVG Profit: {profit}, AVG Number of Trades: {n_trades}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
